{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa7aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "__author__ = \"Shweta Patwa, Danyu Sun\"\n",
    "\n",
    "import csv\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "# import seaborn as sns; sns.set_theme(color_codes=True)\n",
    "import sys\n",
    "import textwrap\n",
    "import time\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# plt.style.use('seaborn-deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ceccc",
   "metadata": {},
   "source": [
    "# Plot histogram on $A_i$ in $D$ and $D_s$ for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01011ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_both_hist(df, df_D_s, A_i, dom_A_i):\n",
    "    # https://stackoverflow.com/questions/6871201/plot-two-histograms-on-single-chart-with-matplotlib\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    bins = np.linspace(start = 0, stop = max(max(df[A_i].tolist()), max(df_D_s[A_i].tolist())) + 1)\n",
    "    plt.hist([df[A_i], df_D_s[A_i]], bins, label=['$D$', '$D_s$'])\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5a7713",
   "metadata": {},
   "source": [
    "# (Non-private) Functions to compute:\n",
    "- Count query q\n",
    "- Sum query q\n",
    "- Median query q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b9ade0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection predicate is conjunctive\n",
    "def helper_apply_pred(data_df, q):\n",
    "    df_for_q = data_df\n",
    "    for k, v in q.items():\n",
    "        for clause in v:\n",
    "            ineq = clause[0]\n",
    "            if ineq == '<':\n",
    "                df_for_q = df_for_q[df_for_q[k] < clause[1]]\n",
    "            elif ineq == '<=':\n",
    "                df_for_q = df_for_q[df_for_q[k] <= clause[1]]\n",
    "            elif ineq == '>':\n",
    "                df_for_q = df_for_q[df_for_q[k] > clause[1]]\n",
    "            elif ineq == '>=':\n",
    "                df_for_q = df_for_q[df_for_q[k] >= clause[1]]\n",
    "            elif ineq == '==':\n",
    "                df_for_q = df_for_q[df_for_q[k] == clause[1]]\n",
    "            elif ineq == '!=':\n",
    "                df_for_q = df_for_q[df_for_q[k] != clause[1]]\n",
    "            else:\n",
    "                print(\"Check query!!!\")\n",
    "    return df_for_q\n",
    "\n",
    "# For a counting query at a time (selection predicate is conjunctive)\n",
    "def get_query_result(data_df, q):\n",
    "    return helper_apply_pred(data_df, q).shape[0]\n",
    "\n",
    "# For sum with selection  (selection predicate is conjunctive)\n",
    "def get_sum(data_df, q, A_i):\n",
    "    df_for_q = helper_apply_pred(data_df, q)\n",
    "    return df_for_q[A_i].sum()\n",
    "\n",
    "# Assume - median is the elem in A_i with rank m\n",
    "def get_median(data_df, q, A_i):\n",
    "    df_for_q = helper_apply_pred(data_df, q)\n",
    "    m = math.ceil(df_for_q.shape[0]/2)\n",
    "    return sorted(list(df_for_q[A_i]))[m - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc8ca2",
   "metadata": {},
   "source": [
    "---\n",
    "# Read $D$ and $D_s$\n",
    "- $D$ is derived from the IPUMS-CPS data\n",
    "- $D_s$ generated using PrivBayes from SDGym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c46be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/yuchaotao/Private-Explanation-System/blob/main/data/ipums/explore.ipynb\n",
    "code_dict = {'RELATE': {101: 'Head/householder',\n",
    "    201: 'Spouse',\n",
    "    202: 'Opposite sex spouse',\n",
    "    203: 'Same sex spouse',\n",
    "    301: 'Child',\n",
    "    303: 'Stepchild',\n",
    "    501: 'Parent',\n",
    "    701: 'Sibling',\n",
    "    901: 'Grandchild',\n",
    "    1001: 'Other relatives, n.s.',\n",
    "    1113: 'Partner/roommate',\n",
    "    1114: 'Unmarried partner',\n",
    "    1116: 'Opposite sex unmarried partner',\n",
    "    1117: 'Same sex unmarried partner',\n",
    "    1115: 'Housemate/roomate',\n",
    "    1241: 'Roomer/boarder/lodger',\n",
    "    1242: 'Foster children',\n",
    "    1260: 'Other nonrelatives',\n",
    "    9100: 'Armed Forces, relationship unknown',\n",
    "    9200: 'Age under 14, relationship unknown',\n",
    "    9900: 'Relationship unknown',\n",
    "    9999: 'NIU'},\n",
    "    'SEX': {1: 'Male', 2: 'Female', 9: 'NIU'},\n",
    "    'RACE': {100: 'White',\n",
    "    200: 'Black',\n",
    "    300: 'American Indian/Aleut/Eskimo',\n",
    "    650: 'Asian or Pacific Islander',\n",
    "    651: 'Asian only',\n",
    "    652: 'Hawaiian/Pacific Islander only',\n",
    "    700: 'Other (single) race, n.e.c.',\n",
    "    801: 'White-Black',\n",
    "    802: 'White-American Indian',\n",
    "    803: 'White-Asian',\n",
    "    804: 'White-Hawaiian/Pacific Islander',\n",
    "    805: 'Black-American Indian',\n",
    "    806: 'Black-Asian',\n",
    "    807: 'Black-Hawaiian/Pacific Islander',\n",
    "    808: 'American Indian-Asian',\n",
    "    809: 'Asian-Hawaiian/Pacific Islander',\n",
    "    810: 'White-Black-American Indian',\n",
    "    811: 'White-Black-Asian',\n",
    "    812: 'White-American Indian-Asian',\n",
    "    813: 'White-Asian-Hawaiian/Pacific Islander',\n",
    "    814: 'White-Black-American Indian-Asian',\n",
    "    815: 'American Indian-Hawaiian/Pacific Islander',\n",
    "    816: 'White-Black--Hawaiian/Pacific Islander',\n",
    "    817: 'White-American Indian-Hawaiian/Pacific Islander',\n",
    "    818: 'Black-American Indian-Asian',\n",
    "    819: 'White-American Indian-Asian-Hawaiian/Pacific Islander',\n",
    "    820: 'Two or three races, unspecified',\n",
    "    830: 'Four or five races, unspecified',\n",
    "    999: 'Blank'},\n",
    "    'MARST': {1: 'Married, spouse present',\n",
    "    2: 'Married, spouse absent',\n",
    "    3: 'Separated',\n",
    "    4: 'Divorced',\n",
    "    5: 'Widowed',\n",
    "    6: 'Never married/single',\n",
    "    7: 'Widowed or Divorced',\n",
    "    9: 'NIU'},\n",
    "    'CITIZEN': {1: 'Born in U.S',\n",
    "    2: 'Born in U.S. outlying',\n",
    "    3: 'Born abroad of American parents',\n",
    "    4: 'Naturalized citizen',\n",
    "    5: 'Not a citizen',\n",
    "    9: 'NIU'},\n",
    "    'WORKLY': {0: 'NIU',\n",
    "    1: 'No',\n",
    "    2: 'Yes'},\n",
    "    'CLASSWKR': {0: 'NIU',\n",
    "    10: 'Self-employed',\n",
    "    13: 'Self-employed, not incorporated',\n",
    "    14: 'Self-employed, incorporated',\n",
    "    20: 'Works for wages or salary',\n",
    "    21: 'Wage/salary, private',\n",
    "    22: 'Private, for profit',\n",
    "    23: 'Private, nonprofit',\n",
    "    24: 'Wage/salary, government',\n",
    "    25: 'Federal government employee',\n",
    "    26: 'Armed forces',\n",
    "    27: 'State government employee',\n",
    "    28: 'Local government employee',\n",
    "    29: 'Unpaid family worker',\n",
    "    99: 'Missing/Unknown'},\n",
    "    'EDUC': {0: 'NIU or no schooling',\n",
    "    1: 'NIU or blank',\n",
    "    2: 'None or preschool',\n",
    "    10: 'Grades 1, 2, 3, or 4',\n",
    "    11: 'Grade 1',\n",
    "    12: 'Grade 2',\n",
    "    13: 'Grade 3',\n",
    "    14: 'Grade 4',\n",
    "    20: 'Grades 5 or 6',\n",
    "    21: 'Grade 5',\n",
    "    22: 'Grade 6',\n",
    "    30: 'Grades 7 or 8',\n",
    "    31: 'Grade 7',\n",
    "    32: 'Grade 8',\n",
    "    40: 'Grade 9',\n",
    "    50: 'Grade 10',\n",
    "    60: 'Grade 11',\n",
    "    70: 'Grade 12',\n",
    "    71: '12th grade, no diploma',\n",
    "    72: '12th grade, diploma unclear',\n",
    "    73: 'High school diploma or equivalent',\n",
    "    80: '1 year of college',\n",
    "    81: 'Some college but no degree',\n",
    "    90: '2 years of college',\n",
    "    91: \"Associate's degree, occupational/vocational program\",\n",
    "    92: \"Associate's degree, academic program\",\n",
    "    100: '3 years of college',\n",
    "    110: '4 years of college',\n",
    "    111: \"Bachelor's degree\",\n",
    "    120: '5+ years of college',\n",
    "    121: '5 years of college',\n",
    "    122: '6+ years of college',\n",
    "    123: \"Master's degree\",\n",
    "    124: 'Professional school degree',\n",
    "    125: 'Doctorate degree',\n",
    "    999: 'Missing/Unknown'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2142fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RELATE', 'AGE', 'SEX', 'RACE', 'MARST', 'CITIZEN', 'CLASSWKR', 'EDUC', 'WORKLY', 'INCTOT']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./2011_2019_D.csv\")\n",
    "col_names = list(df.columns)\n",
    "print(col_names)\n",
    "\n",
    "rel = list(code_dict['RELATE'].values())\n",
    "age = [i for i in range(0, 80)] + [80, 85] # https://cps.ipums.org/cps-action/variables/AGE#codes_section\n",
    "sex = list(code_dict['SEX'].values())\n",
    "rac = list(code_dict['RACE'].values())\n",
    "mar = list(code_dict['MARST'].values())\n",
    "cit = list(code_dict['CITIZEN'].values())\n",
    "wor = list(code_dict['WORKLY'].values())\n",
    "cla = list(code_dict['CLASSWKR'].values())\n",
    "edu = list(code_dict['EDUC'].values())\n",
    "inc = [0, 500000] # https://cps.ipums.org/cps-action/variables/INCTOT#codes_section\n",
    "\n",
    "df_D_s = pd.read_csv(\"./2011_2019_D_s.csv\")\n",
    "df_D_s['AGE'] = df_D_s['AGE'].astype(int)\n",
    "df_D_s['INCTOT'] = df_D_s['INCTOT'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f7c1da",
   "metadata": {},
   "source": [
    "---\n",
    "# Variables $\\epsilon, \\tau$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f27f19f",
   "metadata": {},
   "source": [
    "# Detect FP/FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596b5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FP_FN(re, q_D, q_D_s, tau):\n",
    "    if (re == 0 and (q_D_s - tau < q_D and q_D < q_D_s + tau)):\n",
    "        return 'FN'\n",
    "    if (re == 1 and (q_D <= q_D_s - tau or q_D >= q_D_s + tau)):\n",
    "        return 'FP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792ca20",
   "metadata": {},
   "source": [
    "# $EM_{med}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c57366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_EM_pr(q, A_i, dom_A_i, df, eps, f_handle):\n",
    "    n = get_query_result(df, q)\n",
    "    \n",
    "    rank = {}\n",
    "    score = {}\n",
    "    prob = {}\n",
    "    for i in dom_A_i:\n",
    "        new_conjunct = copy.deepcopy(q)\n",
    "        if A_i in new_conjunct:\n",
    "            new_conjunct[A_i].append(['<', i])\n",
    "        else:\n",
    "            new_conjunct[A_i] = [['<', i]]\n",
    "#         print(\"(EM Pr) %s\" %(new_conjunct))\n",
    "        \n",
    "        rank[i] = get_query_result(df, new_conjunct)\n",
    "        score[i] = -1*abs(rank[i] - n/2)\n",
    "        prob[i] = np.exp(eps*score[i]/2)\n",
    "#         print(\"%s: %s\\t %s\\t %s\" %(i, rank[i], score[i], prob[i]))\n",
    "    \n",
    "    lst = list(prob.keys())\n",
    "    pr = list(prob.values())\n",
    "    tot = sum(pr)\n",
    "    pr = [pr[i]/tot for i in range(len(pr))]\n",
    "    \n",
    "#     for i in range(len(lst)):\n",
    "#         elem = lst[i]\n",
    "#         f_handle.write(\"%s\\t\\t%s\\t\\t%s\\t\\t%.10f\\n\" %(elem, rank[elem], score[elem], pr[i]))\n",
    "#     f_handle.write(\"\\n\")\n",
    "    return lst, pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02332b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emmed(q, A_i, dom_A_i, df, df_D_s, tau, eps, lst, pr, f_handle):\n",
    "    re = -1\n",
    "    \n",
    "    q_D = get_median(df, q, A_i)\n",
    "    q_D_s = get_median(df_D_s, q, A_i)\n",
    "    l = q_D_s - tau\n",
    "    r = q_D_s + tau\n",
    "    \n",
    "    f_handle.write(\"(I = (%s, %s), q(D) = %s, Truth = %s, eps = %s) Algo returns:\\n\" \n",
    "          %(l, r, q_D, \"Distance bound satisfied\" if (l < q_D and q_D < r) else \"Distance bound unmet\", eps))\n",
    "    # ----------------------------------------------------------------------------------------------------------------\n",
    "    ans = random.choices(lst, weights = pr)[0]\n",
    "    f_handle.write(\"\\tDP estimate = %s\\n\" %(ans))\n",
    "    \n",
    "    re = (l < ans and ans < r)\n",
    "    if re == 0:\n",
    "        f_handle.write(\"Distance bound unmet\\n\")\n",
    "    else:\n",
    "        f_handle.write(\"Distance bound satisfied\\n\")\n",
    "    return re, q_D, q_D_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e08aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_emmed(q, A_i, dom_A_i, df, df_D_s, tau, eps, f_handle):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    lst, pr = helper_EM_pr(q, A_i, dom_A_i, df, eps, f_handle)\n",
    "    \n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    for i in range(100):\n",
    "        re, q_D, q_D_s = emmed(q, A_i, dom_A_i, df, df_D_s, tau, eps, lst, pr, f_handle)\n",
    "        tmp = FP_FN(re, q_D, q_D_s, tau)\n",
    "        if tmp == 'FN':\n",
    "            FN += 1\n",
    "        if tmp == 'FP':\n",
    "            FP += 1\n",
    "    err = (FN + FP)/100\n",
    "    f_handle.write(\"\\n\")\n",
    "    \n",
    "    print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e27e834",
   "metadata": {},
   "source": [
    "# $Hist_{med}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48682cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histmed(q, A_i, df, df_D_s, tau, eps, f_handle):\n",
    "    re = -1\n",
    "    \n",
    "    q_D = get_median(df, q, A_i)\n",
    "    q_D_s = get_median(df_D_s, q, A_i)\n",
    "    l = q_D_s - tau\n",
    "    r = q_D_s + tau\n",
    "    \n",
    "    nu_q = np.random.laplace(scale = 1/(eps/2))\n",
    "    m = math.ceil((get_query_result(df, q) + nu_q)/2)\n",
    "    \n",
    "    f_handle.write(\"(I = (%s, %s), q(D) = %s, Truth = %s, eps = %s) Algo returns:\\n\" \n",
    "          %(l, r, q_D, \"Distance bound satisfied\" if (l < q_D and q_D < r) else \"Distance bound unmet\", eps))\n",
    "    # ----------------------------------------------------------------------------------------------------------------\n",
    "    new_conjunct = copy.deepcopy(q)\n",
    "    if A_i in new_conjunct:\n",
    "        new_conjunct[A_i].append(['<=', l])\n",
    "    else:\n",
    "        new_conjunct[A_i] = [['<=', l]]\n",
    "#     print(\"(Hist) %s\" %(new_conjunct))\n",
    "    q1 = get_query_result(df, new_conjunct)\n",
    "    nu_q1 = np.random.laplace(scale = 1/(eps/2))\n",
    "    f_handle.write(\"\\tDP estimate q1 = %s + %s = %s\\t\\t vs %s\\n\" %(q1, nu_q1, q1 + nu_q1, m))\n",
    "    \n",
    "    new_conjunct = {}\n",
    "    new_conjunct = copy.deepcopy(q)\n",
    "    if A_i in new_conjunct:\n",
    "        new_conjunct[A_i].append(['>=', r])\n",
    "    else:\n",
    "        new_conjunct[A_i] = [['>=', r]]\n",
    "#     print(\"(Hist) %s\\n\" %(new_conjunct))\n",
    "    q2 = get_query_result(df, new_conjunct)\n",
    "    nu_q2 = np.random.laplace(scale = 1/(eps/2))\n",
    "    f_handle.write(\"\\tDP estimate q2 = %s + %s = %s\\t\\t vs %s\\n\" %(q2, nu_q2, q2 + nu_q2, m))\n",
    "\n",
    "    if q1 + nu_q1 >= m:\n",
    "        f_handle.write(\"Distance bound unmet\\n\")\n",
    "        re = 0\n",
    "    elif q2 + nu_q2 >=  m:\n",
    "        f_handle.write(\"Distance bound unmet\\n\")\n",
    "        re = 0\n",
    "    else:\n",
    "        f_handle.write(\"Distance bound satisfied\\n\")\n",
    "        re = 1\n",
    "    return re, q_D, q_D_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5279789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_histmed(q, A_i, df, df_D_s, tau, eps, f_handle):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    for i in range(100):\n",
    "        re, q_D, q_D_s = histmed(q, A_i, df, df_D_s, tau, eps, f_handle)\n",
    "        tmp = FP_FN(re, q_D, q_D_s, tau)\n",
    "        if tmp == 'FN':\n",
    "            FN += 1\n",
    "        if tmp == 'FP':\n",
    "            FP += 1\n",
    "    err = (FN + FP)/100\n",
    "    f_handle.write(\"\\n\")\n",
    "    \n",
    "    print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb690c4",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 9 queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd1fc712",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = {'WORKLY': [['==', 'Yes']], 'CLASSWKR': [['==', 'Wage/salary, private']], 'EDUC': [['==', \"Bachelor's degree\"]]}  #60\n",
    "q2 = {'SEX': [['==', 'Male']], 'RACE': [['==', 'White-Black']], 'RELATE': [['==', 'Spouse']]}\n",
    "q3 = {'SEX': [['==', 'Male']], 'RACE': [['==', 'Black']], 'CLASSWKR': [['==', 'Wage/salary, private']]}\n",
    "q4 = {'SEX': [['==', 'Female']], 'RACE': [['==', 'Black']], 'WORKLY': [['==', 'Yes']]}\n",
    "q5 = {'SEX': [['==', 'Female']], 'EDUC': [['==', \"Some college but no degree\"]], 'MARST': [['==', 'Married, spouse absent']]}\n",
    "q6 = {'SEX': [['==', 'Male']], 'CITIZEN': [['==', \"Born in U.S\"]], 'WORKLY': [['==', 'Yes']]}\n",
    "q7 = {'RACE': [['==', 'Asian only']], 'MARST': [['==', \"Separated\"]], 'CITIZEN': [['==', 'Born in U.S']]}\n",
    "q8 = {'SEX': [['==', 'Male']], 'RACE': [['==', \"White\"]], 'CLASSWKR': [['==', \"Wage/salary, private\"]]}\n",
    "q9 = {'WORKLY': [['==', 'Yes']], 'CLASSWKR': [['==', \"Armed forces\"]], 'EDUC': [['==', \"Doctorate degree\"]]}\n",
    "\n",
    "queries =  [q1, q2, q3, q4, q5, q6, q7, q8, q9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3432499f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q(D)</th>\n",
       "      <th>q(D_s)</th>\n",
       "      <th>n_prime</th>\n",
       "      <th>0.002</th>\n",
       "      <th>0.008</th>\n",
       "      <th>0.032</th>\n",
       "      <th>0.128</th>\n",
       "      <th>0.512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q1</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>126890</td>\n",
       "      <td>0.082_(40.918,41.082)</td>\n",
       "      <td>0.328_(40.672,41.328)</td>\n",
       "      <td>1.312_(39.688,42.312)</td>\n",
       "      <td>5.248_(35.752,46.248)</td>\n",
       "      <td>20.992_(20.008,61.992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q2</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>253</td>\n",
       "      <td>0.08_(39.92,40.08)</td>\n",
       "      <td>0.32_(39.68,40.32)</td>\n",
       "      <td>1.28_(38.72,41.28)</td>\n",
       "      <td>5.12_(34.88,45.12)</td>\n",
       "      <td>20.48_(19.52,60.48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q3</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>33239</td>\n",
       "      <td>0.08_(39.92,40.08)</td>\n",
       "      <td>0.32_(39.68,40.32)</td>\n",
       "      <td>1.28_(38.72,41.28)</td>\n",
       "      <td>5.12_(34.88,45.12)</td>\n",
       "      <td>20.48_(19.52,60.48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q4</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>51352</td>\n",
       "      <td>0.082_(40.918,41.082)</td>\n",
       "      <td>0.328_(40.672,41.328)</td>\n",
       "      <td>1.312_(39.688,42.312)</td>\n",
       "      <td>5.248_(35.752,46.248)</td>\n",
       "      <td>20.992_(20.008,61.992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q5</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1653</td>\n",
       "      <td>0.08_(39.92,40.08)</td>\n",
       "      <td>0.32_(39.68,40.32)</td>\n",
       "      <td>1.28_(38.72,41.28)</td>\n",
       "      <td>5.12_(34.88,45.12)</td>\n",
       "      <td>20.48_(19.52,60.48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q6</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>358766</td>\n",
       "      <td>0.082_(40.918,41.082)</td>\n",
       "      <td>0.328_(40.672,41.328)</td>\n",
       "      <td>1.312_(39.688,42.312)</td>\n",
       "      <td>5.248_(35.752,46.248)</td>\n",
       "      <td>20.992_(20.008,61.992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q7</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>195</td>\n",
       "      <td>0.078_(38.922,39.078)</td>\n",
       "      <td>0.312_(38.688,39.312)</td>\n",
       "      <td>1.248_(37.752,40.248)</td>\n",
       "      <td>4.992_(34.008,43.992)</td>\n",
       "      <td>19.968_(19.032,58.968)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q8</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>267261</td>\n",
       "      <td>0.08_(39.92,40.08)</td>\n",
       "      <td>0.32_(39.68,40.32)</td>\n",
       "      <td>1.28_(38.72,41.28)</td>\n",
       "      <td>5.12_(34.88,45.12)</td>\n",
       "      <td>20.48_(19.52,60.48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q9</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>87</td>\n",
       "      <td>0.08_(39.92,40.08)</td>\n",
       "      <td>0.32_(39.68,40.32)</td>\n",
       "      <td>1.28_(38.72,41.28)</td>\n",
       "      <td>5.12_(34.88,45.12)</td>\n",
       "      <td>20.48_(19.52,60.48)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    q(D)  q(D_s)  n_prime                  0.002                  0.008  \\\n",
       "q1    41      41   126890  0.082_(40.918,41.082)  0.328_(40.672,41.328)   \n",
       "q2    40      40      253     0.08_(39.92,40.08)     0.32_(39.68,40.32)   \n",
       "q3    40      40    33239     0.08_(39.92,40.08)     0.32_(39.68,40.32)   \n",
       "q4    41      41    51352  0.082_(40.918,41.082)  0.328_(40.672,41.328)   \n",
       "q5    40      40     1653     0.08_(39.92,40.08)     0.32_(39.68,40.32)   \n",
       "q6    41      41   358766  0.082_(40.918,41.082)  0.328_(40.672,41.328)   \n",
       "q7    39      39      195  0.078_(38.922,39.078)  0.312_(38.688,39.312)   \n",
       "q8    40      40   267261     0.08_(39.92,40.08)     0.32_(39.68,40.32)   \n",
       "q9    40      40       87     0.08_(39.92,40.08)     0.32_(39.68,40.32)   \n",
       "\n",
       "                    0.032                  0.128                   0.512  \n",
       "q1  1.312_(39.688,42.312)  5.248_(35.752,46.248)  20.992_(20.008,61.992)  \n",
       "q2     1.28_(38.72,41.28)     5.12_(34.88,45.12)     20.48_(19.52,60.48)  \n",
       "q3     1.28_(38.72,41.28)     5.12_(34.88,45.12)     20.48_(19.52,60.48)  \n",
       "q4  1.312_(39.688,42.312)  5.248_(35.752,46.248)  20.992_(20.008,61.992)  \n",
       "q5     1.28_(38.72,41.28)     5.12_(34.88,45.12)     20.48_(19.52,60.48)  \n",
       "q6  1.312_(39.688,42.312)  5.248_(35.752,46.248)  20.992_(20.008,61.992)  \n",
       "q7  1.248_(37.752,40.248)  4.992_(34.008,43.992)  19.968_(19.032,58.968)  \n",
       "q8     1.28_(38.72,41.28)     5.12_(34.88,45.12)     20.48_(19.52,60.48)  \n",
       "q9     1.28_(38.72,41.28)     5.12_(34.88,45.12)     20.48_(19.52,60.48)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_frac = [0.002, 0.008, 0.032, 0.128, 0.512]\n",
    "mydata = []\n",
    "for i in range(len(queries)):\n",
    "    tmp = []\n",
    "    q_D = get_median(df, queries[i], 'AGE')\n",
    "    q_Ds = get_median(df_D_s, queries[i], 'AGE')\n",
    "    n_p = get_query_result(df, queries[i])\n",
    "    tmp.append(q_D)\n",
    "    tmp.append(q_Ds)\n",
    "    tmp.append(n_p)\n",
    "    str_ = ''\n",
    "    for j in tau_frac:\n",
    "        str_ = str(j*q_Ds) + '_('+ str(round(q_Ds - j*q_Ds, 3)) + ',' + str(round(q_Ds + j*q_Ds, 3)) + ')'\n",
    "        tmp.append(str_)\n",
    "    mydata.append(tmp)\n",
    "\n",
    "mydata = pd.DataFrame(mydata, index =['q1', 'q2', 'q3', 'q4', 'q5', 'q6', 'q7', 'q8', 'q9'],\n",
    "                              columns =['q(D)', 'q(D_s)','n_prime', 0.002, 0.008, 0.032, 0.128, 0.512])\n",
    "mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa56de",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7261357",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_frac = [0.002, 0.008, 0.032, 0.128, 0.512]   \n",
    "default_eps = 0.25\n",
    "\n",
    "eps = [0.0625, 0.125, 0.25, 0.5, 1]   \n",
    "default_tau = 0.032\n",
    "\n",
    "delta = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ce6642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_EM_vary_tau = [[], [], [], [], [], [], [], [], []]\n",
    "lst_EM_vary_eps = [[], [], [], [], [], [], [], [], []]\n",
    "\n",
    "lst_Hist_vary_tau = [[], [], [], [], [], [], [], [], []]\n",
    "lst_Hist_vary_eps = [[], [], [], [], [], [], [], [], []]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a280d1b6",
   "metadata": {},
   "source": [
    "# EM---vary tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86be957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 76.12823128700256 seconds ----\n",
      "---- 76.31841397285461 seconds ----\n",
      "---- 76.14160513877869 seconds ----\n",
      "---- 76.07816505432129 seconds ----\n",
      "---- 76.59980082511902 seconds ----\n",
      "\n",
      "---- 40.52935194969177 seconds ----\n",
      "---- 40.64575409889221 seconds ----\n",
      "---- 40.61345410346985 seconds ----\n",
      "---- 40.641660928726196 seconds ----\n",
      "---- 41.028985261917114 seconds ----\n",
      "\n",
      "---- 46.41013193130493 seconds ----\n",
      "---- 45.98005199432373 seconds ----\n",
      "---- 46.01666617393494 seconds ----\n",
      "---- 45.980655670166016 seconds ----\n",
      "---- 45.9067440032959 seconds ----\n",
      "\n",
      "---- 49.54567098617554 seconds ----\n",
      "---- 49.443907022476196 seconds ----\n",
      "---- 49.55816388130188 seconds ----\n",
      "---- 49.52587008476257 seconds ----\n",
      "---- 49.489394187927246 seconds ----\n",
      "\n",
      "---- 48.314019203186035 seconds ----\n",
      "---- 48.26707100868225 seconds ----\n",
      "---- 48.34895205497742 seconds ----\n",
      "---- 48.32034993171692 seconds ----\n",
      "---- 48.34060072898865 seconds ----\n",
      "\n",
      "---- 77.61828303337097 seconds ----\n",
      "---- 78.03204798698425 seconds ----\n",
      "---- 77.6605498790741 seconds ----\n",
      "---- 77.53654909133911 seconds ----\n",
      "---- 77.59773302078247 seconds ----\n",
      "\n",
      "---- 20.163804054260254 seconds ----\n",
      "---- 20.166215896606445 seconds ----\n",
      "---- 20.21407675743103 seconds ----\n",
      "---- 20.209309816360474 seconds ----\n",
      "---- 20.152618885040283 seconds ----\n",
      "\n",
      "---- 73.0129828453064 seconds ----\n",
      "---- 73.22278571128845 seconds ----\n",
      "---- 72.55085802078247 seconds ----\n",
      "---- 72.48695611953735 seconds ----\n",
      "---- 72.6134729385376 seconds ----\n",
      "\n",
      "---- 47.97141408920288 seconds ----\n",
      "---- 47.77631092071533 seconds ----\n",
      "---- 48.07975101470947 seconds ----\n",
      "---- 48.04790925979614 seconds ----\n",
      "---- 47.898324966430664 seconds ----\n",
      "\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0], [0.73, 0.69, 0.32, 0.01, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 0.0, 0.0, 0.0], [0.7, 0.66, 0.0, 0.0, 0.0], [1.0, 1.0, 0.0, 0.0, 0.0], [0.86, 0.88, 0.61, 0.18, 0.01], [1.0, 1.0, 0.0, 0.0, 0.0], [0.81, 0.82, 0.49, 0.16, 0.02]]\n"
     ]
    }
   ],
   "source": [
    "f_handle = open('median_EM_vary_tau.txt', 'w')\n",
    "num = 0\n",
    "for i in queries:\n",
    "    f_handle.write(\"%s\\n\" %(i))\n",
    "    q_D_s = get_median(df_D_s, i, 'AGE')\n",
    "    lst_EM_vary_tau[num].append(err_emmed(i, 'AGE', age, df, df_D_s, tau_frac[0]*q_D_s, default_eps, f_handle))\n",
    "    lst_EM_vary_tau[num].append(err_emmed(i, 'AGE', age, df, df_D_s, tau_frac[1]*q_D_s, default_eps, f_handle))\n",
    "    lst_EM_vary_tau[num].append(err_emmed(i, 'AGE', age, df, df_D_s, tau_frac[2]*q_D_s, default_eps, f_handle))\n",
    "    lst_EM_vary_tau[num].append(err_emmed(i, 'AGE', age, df, df_D_s, tau_frac[3]*q_D_s, default_eps, f_handle))\n",
    "    lst_EM_vary_tau[num].append(err_emmed(i, 'AGE', age, df, df_D_s, tau_frac[4]*q_D_s, default_eps, f_handle))\n",
    "    print()\n",
    "    num = num + 1\n",
    "f_handle.close()\n",
    "\n",
    "print(lst_EM_vary_tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff3fe9",
   "metadata": {},
   "source": [
    "# EM---vary eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38d4dcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 77.69385814666748 seconds ----\n",
      "---- 77.45881795883179 seconds ----\n",
      "---- 77.18001294136047 seconds ----\n",
      "---- 77.15594387054443 seconds ----\n",
      "---- 77.30112886428833 seconds ----\n",
      "\n",
      "---- 41.11814594268799 seconds ----\n",
      "---- 40.679636001586914 seconds ----\n",
      "---- 40.72119331359863 seconds ----\n",
      "---- 40.65622401237488 seconds ----\n",
      "---- 40.772562980651855 seconds ----\n",
      "\n",
      "---- 45.989054918289185 seconds ----\n",
      "---- 45.80917501449585 seconds ----\n",
      "---- 45.86086392402649 seconds ----\n",
      "---- 45.89493799209595 seconds ----\n",
      "---- 45.88972306251526 seconds ----\n",
      "\n",
      "---- 49.40224885940552 seconds ----\n",
      "---- 49.42267394065857 seconds ----\n",
      "---- 49.23490500450134 seconds ----\n",
      "---- 49.476637840270996 seconds ----\n",
      "---- 49.51488423347473 seconds ----\n",
      "\n",
      "---- 48.73547005653381 seconds ----\n",
      "---- 48.48579287528992 seconds ----\n",
      "---- 48.71938395500183 seconds ----\n",
      "---- 48.46637320518494 seconds ----\n",
      "---- 48.14233589172363 seconds ----\n",
      "\n",
      "---- 77.83130502700806 seconds ----\n",
      "---- 77.59530377388 seconds ----\n",
      "---- 77.2363851070404 seconds ----\n",
      "---- 77.17693090438843 seconds ----\n",
      "---- 77.17652201652527 seconds ----\n",
      "\n",
      "---- 20.089107990264893 seconds ----\n",
      "---- 20.15335726737976 seconds ----\n",
      "---- 20.0921471118927 seconds ----\n",
      "---- 20.059288024902344 seconds ----\n",
      "---- 20.085780143737793 seconds ----\n",
      "\n",
      "---- 72.51068711280823 seconds ----\n",
      "---- 72.51410007476807 seconds ----\n",
      "---- 72.50843811035156 seconds ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/7ltwlxyn2rsfmwwm5nltr1pr0000gn/T/ipykernel_96455/1738381470.py:23: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  pr = [pr[i]/tot for i in range(len(pr))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 72.46576070785522 seconds ----\n",
      "---- 72.40935707092285 seconds ----\n",
      "\n",
      "---- 47.34933304786682 seconds ----\n",
      "---- 47.404834032058716 seconds ----\n",
      "---- 47.367918968200684 seconds ----\n",
      "---- 47.365243911743164 seconds ----\n",
      "---- 47.389281034469604 seconds ----\n",
      "\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0], [0.72, 0.52, 0.37, 0.1, 0.03], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.31, 0.14, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.86, 0.7, 0.51, 0.29, 0.03], [0.0, 0.0, 0.0, 1.0, 1.0], [0.9, 0.78, 0.62, 0.3, 0.11]]\n"
     ]
    }
   ],
   "source": [
    "f_handle = open('median_EM_vary_eps.txt', 'w')\n",
    "num = 0\n",
    "for i in queries:\n",
    "    f_handle.write(\"%s\\n\" %(i))\n",
    "    q_D_s = get_median(df_D_s, i, 'AGE')\n",
    "    lst_EM_vary_eps[num].append(err_emmed(i,'AGE', age, df, df_D_s, default_tau*q_D_s, eps[0], f_handle))\n",
    "    lst_EM_vary_eps[num].append(err_emmed(i,'AGE', age, df, df_D_s, default_tau*q_D_s, eps[1], f_handle))\n",
    "    lst_EM_vary_eps[num].append(err_emmed(i,'AGE', age, df, df_D_s, default_tau*q_D_s, eps[2], f_handle))\n",
    "    lst_EM_vary_eps[num].append(err_emmed(i,'AGE', age, df, df_D_s, default_tau*q_D_s, eps[3], f_handle))\n",
    "    lst_EM_vary_eps[num].append(err_emmed(i,'AGE', age, df, df_D_s, default_tau*q_D_s, eps[4], f_handle))\n",
    "    print()\n",
    "    num = num + 1\n",
    "f_handle.close()\n",
    "\n",
    "print(lst_EM_vary_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66e3c87",
   "metadata": {},
   "source": [
    "# Hist---vary tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbdaf39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 133.28719902038574 seconds ----\n",
      "---- 133.30722284317017 seconds ----\n",
      "---- 133.24568009376526 seconds ----\n",
      "---- 133.07084798812866 seconds ----\n",
      "---- 132.37571620941162 seconds ----\n",
      "\n",
      "---- 71.4096291065216 seconds ----\n",
      "---- 71.3939483165741 seconds ----\n",
      "---- 71.4008629322052 seconds ----\n",
      "---- 71.38017296791077 seconds ----\n",
      "---- 71.42420721054077 seconds ----\n",
      "\n",
      "---- 80.01199793815613 seconds ----\n",
      "---- 80.00273513793945 seconds ----\n",
      "---- 79.99132490158081 seconds ----\n",
      "---- 79.96221971511841 seconds ----\n",
      "---- 79.7936429977417 seconds ----\n",
      "\n",
      "---- 85.88692712783813 seconds ----\n",
      "---- 85.95404291152954 seconds ----\n",
      "---- 85.90589213371277 seconds ----\n",
      "---- 85.85199999809265 seconds ----\n",
      "---- 85.64142107963562 seconds ----\n",
      "\n",
      "---- 84.64307689666748 seconds ----\n",
      "---- 84.64207983016968 seconds ----\n",
      "---- 84.66582179069519 seconds ----\n",
      "---- 84.63913607597351 seconds ----\n",
      "---- 84.65088987350464 seconds ----\n",
      "\n",
      "---- 130.18317699432373 seconds ----\n",
      "---- 130.15702414512634 seconds ----\n",
      "---- 130.22058296203613 seconds ----\n",
      "---- 129.77563905715942 seconds ----\n",
      "---- 128.07904481887817 seconds ----\n",
      "\n",
      "---- 35.348172664642334 seconds ----\n",
      "---- 35.34577298164368 seconds ----\n",
      "---- 35.36134195327759 seconds ----\n",
      "---- 35.413455963134766 seconds ----\n",
      "---- 35.383776903152466 seconds ----\n",
      "\n",
      "---- 124.46987795829773 seconds ----\n",
      "---- 124.94392204284668 seconds ----\n",
      "---- 124.08444738388062 seconds ----\n",
      "---- 124.1157341003418 seconds ----\n",
      "---- 122.53740692138672 seconds ----\n",
      "\n",
      "---- 84.21200323104858 seconds ----\n",
      "---- 84.23933410644531 seconds ----\n",
      "---- 84.58015990257263 seconds ----\n",
      "---- 86.09988188743591 seconds ----\n",
      "---- 91.69751191139221 seconds ----\n",
      "\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0], [0.55, 0.5, 0.24, 0.0, 0.0], [0.05, 0.02, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.08, 0.12, 0.0, 0.0, 0.0], [0.01, 0.0, 0.0, 0.0, 0.0], [0.57, 0.5, 0.4, 0.21, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.55, 0.52, 0.47, 0.08, 0.01]]\n"
     ]
    }
   ],
   "source": [
    "f_handle = open('median_Hist_vary_tau.txt', 'w')\n",
    "num = 0\n",
    "for i in queries:\n",
    "    f_handle.write(\"%s\\n\" %(i))\n",
    "    q_D_s = get_median(df_D_s, i, 'AGE')\n",
    "    lst_Hist_vary_tau[num].append(err_histmed(i, 'AGE', df, df_D_s, tau_frac[0]*q_D_s, default_eps, f_handle))\n",
    "    lst_Hist_vary_tau[num].append(err_histmed(i, 'AGE', df, df_D_s, tau_frac[1]*q_D_s, default_eps, f_handle))\n",
    "    lst_Hist_vary_tau[num].append(err_histmed(i, 'AGE', df, df_D_s, tau_frac[2]*q_D_s, default_eps, f_handle))\n",
    "    lst_Hist_vary_tau[num].append(err_histmed(i, 'AGE', df, df_D_s, tau_frac[3]*q_D_s, default_eps, f_handle))\n",
    "    lst_Hist_vary_tau[num].append(err_histmed(i, 'AGE', df, df_D_s, tau_frac[4]*q_D_s, default_eps, f_handle))\n",
    "    print()\n",
    "    num = num + 1\n",
    "f_handle.close()\n",
    "\n",
    "print(lst_Hist_vary_tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b5a55",
   "metadata": {},
   "source": [
    "# Hist---vary eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1ff98f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 155.3649880886078 seconds ----\n",
      "---- 186.554869890213 seconds ----\n",
      "---- 143.24581813812256 seconds ----\n",
      "---- 175.7393639087677 seconds ----\n",
      "---- 187.69583106040955 seconds ----\n",
      "\n",
      "---- 104.1426990032196 seconds ----\n",
      "---- 106.35732507705688 seconds ----\n",
      "---- 100.69592595100403 seconds ----\n",
      "---- 100.52722001075745 seconds ----\n",
      "---- 100.91976928710938 seconds ----\n",
      "\n",
      "---- 114.24548768997192 seconds ----\n",
      "---- 114.90965509414673 seconds ----\n",
      "---- 117.06384992599487 seconds ----\n",
      "---- 123.48565196990967 seconds ----\n",
      "---- 111.65394806861877 seconds ----\n",
      "\n",
      "---- 106.51037216186523 seconds ----\n",
      "---- 106.54294180870056 seconds ----\n",
      "---- 106.44451785087585 seconds ----\n",
      "---- 104.06315279006958 seconds ----\n",
      "---- 103.18718695640564 seconds ----\n",
      "\n",
      "---- 102.9418432712555 seconds ----\n",
      "---- 102.649240732193 seconds ----\n",
      "---- 103.25637912750244 seconds ----\n",
      "---- 102.13845872879028 seconds ----\n",
      "---- 100.85428929328918 seconds ----\n",
      "\n",
      "---- 157.36268210411072 seconds ----\n",
      "---- 156.56472492218018 seconds ----\n",
      "---- 158.33441877365112 seconds ----\n",
      "---- 157.41659879684448 seconds ----\n",
      "---- 156.8676347732544 seconds ----\n",
      "\n",
      "---- 43.67718005180359 seconds ----\n",
      "---- 44.45645809173584 seconds ----\n",
      "---- 43.5882842540741 seconds ----\n",
      "---- 43.615127086639404 seconds ----\n",
      "---- 43.66574501991272 seconds ----\n",
      "\n",
      "---- 149.44832015037537 seconds ----\n",
      "---- 150.01756691932678 seconds ----\n",
      "---- 149.08313298225403 seconds ----\n",
      "---- 150.8194179534912 seconds ----\n",
      "---- 148.7279691696167 seconds ----\n",
      "\n",
      "---- 101.59766602516174 seconds ----\n",
      "---- 100.12408494949341 seconds ----\n",
      "---- 99.71001482009888 seconds ----\n",
      "---- 100.72609114646912 seconds ----\n",
      "---- 102.4167857170105 seconds ----\n",
      "\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0], [0.56, 0.49, 0.28, 0.06, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.17, 0.08, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.6, 0.66, 0.37, 0.26, 0.09], [0.0, 0.0, 0.0, 0.0, 0.0], [0.62, 0.5, 0.38, 0.13, 0.06]]\n"
     ]
    }
   ],
   "source": [
    "f_handle = open('median_Hist_vary_eps.txt', 'w')\n",
    "num = 0\n",
    "for i in queries:\n",
    "    f_handle.write(\"%s\\n\" %(i))\n",
    "    q_D_s = get_median(df_D_s, i, 'AGE')\n",
    "    lst_Hist_vary_eps[num].append(err_histmed(i,'AGE', df, df_D_s, default_tau*q_D_s, eps[0], f_handle))\n",
    "    lst_Hist_vary_eps[num].append(err_histmed(i,'AGE', df, df_D_s, default_tau*q_D_s, eps[1], f_handle))\n",
    "    lst_Hist_vary_eps[num].append(err_histmed(i,'AGE', df, df_D_s, default_tau*q_D_s, eps[2], f_handle))\n",
    "    lst_Hist_vary_eps[num].append(err_histmed(i,'AGE', df, df_D_s, default_tau*q_D_s, eps[3], f_handle))\n",
    "    lst_Hist_vary_eps[num].append(err_histmed(i,'AGE', df, df_D_s, default_tau*q_D_s, eps[4], f_handle))\n",
    "    print()\n",
    "    num = num + 1\n",
    "f_handle.close()\n",
    "\n",
    "print(lst_Hist_vary_eps)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2513f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
