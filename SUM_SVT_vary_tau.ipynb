{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa7aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "__author__ = \"Shweta Patwa, Danyu Sun\"\n",
    "\n",
    "import csv\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "# import seaborn as sns; sns.set_theme(color_codes=True)\n",
    "import sys\n",
    "import textwrap\n",
    "import time\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# plt.style.use('seaborn-deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46b1e35",
   "metadata": {},
   "source": [
    "# Plot histogram on $A_i$ in $D$ and $D_s$ for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6efe6f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_both_hist(df, df_D_s, A_i, dom_A_i):\n",
    "    # https://stackoverflow.com/questions/6871201/plot-two-histograms-on-single-chart-with-matplotlib\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    bins = np.linspace(start = 0, stop = max(max(df[A_i].tolist()), max(df_D_s[A_i].tolist())) + 1)\n",
    "    plt.hist([df[A_i], df_D_s[A_i]], bins, label=['$D$', '$D_s$'])\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960cb6cc",
   "metadata": {},
   "source": [
    "# (Non-private) Functions to compute:\n",
    "- Count query q\n",
    "- Sum query q\n",
    "- Median query q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adf2bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection predicate is conjunctive\n",
    "def helper_apply_pred(data_df, q):\n",
    "    df_for_q = data_df\n",
    "    for k, v in q.items():\n",
    "        for clause in v:\n",
    "            ineq = clause[0]\n",
    "            if ineq == '<':\n",
    "                df_for_q = df_for_q[df_for_q[k] < clause[1]]\n",
    "            elif ineq == '<=':\n",
    "                df_for_q = df_for_q[df_for_q[k] <= clause[1]]\n",
    "            elif ineq == '>':\n",
    "                df_for_q = df_for_q[df_for_q[k] > clause[1]]\n",
    "            elif ineq == '>=':\n",
    "                df_for_q = df_for_q[df_for_q[k] >= clause[1]]\n",
    "            elif ineq == '==':\n",
    "                df_for_q = df_for_q[df_for_q[k] == clause[1]]\n",
    "            elif ineq == '!=':\n",
    "                df_for_q = df_for_q[df_for_q[k] != clause[1]]\n",
    "            else:\n",
    "                print(\"Check query!!!\")\n",
    "    return df_for_q\n",
    "\n",
    "# For a counting query at a time (selection predicate is conjunctive)\n",
    "def get_query_result(data_df, q):\n",
    "    return helper_apply_pred(data_df, q).shape[0]\n",
    "\n",
    "# For sum with selection  (selection predicate is conjunctive)\n",
    "def get_sum(data_df, q, A_i):\n",
    "    df_for_q = helper_apply_pred(data_df, q)\n",
    "    return df_for_q[A_i].sum()\n",
    "\n",
    "# Assume - median is the elem in A_i with rank m\n",
    "def get_median(data_df, q, A_i):\n",
    "    df_for_q = helper_apply_pred(data_df, q)\n",
    "    m = math.ceil(df_for_q.shape[0]/2)\n",
    "    return sorted(list(df_for_q[A_i]))[m - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1436d958",
   "metadata": {},
   "source": [
    "---\n",
    "# Read $D$ and $D_s$\n",
    "- $D$ is derived from the IPUMS-CPS data\n",
    "- $D_s$ generated using PrivBayes from SDGym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c468ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/yuchaotao/Private-Explanation-System/blob/main/data/ipums/explore.ipynb\n",
    "code_dict = {'RELATE': {101: 'Head/householder',\n",
    "    201: 'Spouse',\n",
    "    202: 'Opposite sex spouse',\n",
    "    203: 'Same sex spouse',\n",
    "    301: 'Child',\n",
    "    303: 'Stepchild',\n",
    "    501: 'Parent',\n",
    "    701: 'Sibling',\n",
    "    901: 'Grandchild',\n",
    "    1001: 'Other relatives, n.s.',\n",
    "    1113: 'Partner/roommate',\n",
    "    1114: 'Unmarried partner',\n",
    "    1116: 'Opposite sex unmarried partner',\n",
    "    1117: 'Same sex unmarried partner',\n",
    "    1115: 'Housemate/roomate',\n",
    "    1241: 'Roomer/boarder/lodger',\n",
    "    1242: 'Foster children',\n",
    "    1260: 'Other nonrelatives',\n",
    "    9100: 'Armed Forces, relationship unknown',\n",
    "    9200: 'Age under 14, relationship unknown',\n",
    "    9900: 'Relationship unknown',\n",
    "    9999: 'NIU'},\n",
    "    'SEX': {1: 'Male', 2: 'Female', 9: 'NIU'},\n",
    "    'RACE': {100: 'White',\n",
    "    200: 'Black',\n",
    "    300: 'American Indian/Aleut/Eskimo',\n",
    "    650: 'Asian or Pacific Islander',\n",
    "    651: 'Asian only',\n",
    "    652: 'Hawaiian/Pacific Islander only',\n",
    "    700: 'Other (single) race, n.e.c.',\n",
    "    801: 'White-Black',\n",
    "    802: 'White-American Indian',\n",
    "    803: 'White-Asian',\n",
    "    804: 'White-Hawaiian/Pacific Islander',\n",
    "    805: 'Black-American Indian',\n",
    "    806: 'Black-Asian',\n",
    "    807: 'Black-Hawaiian/Pacific Islander',\n",
    "    808: 'American Indian-Asian',\n",
    "    809: 'Asian-Hawaiian/Pacific Islander',\n",
    "    810: 'White-Black-American Indian',\n",
    "    811: 'White-Black-Asian',\n",
    "    812: 'White-American Indian-Asian',\n",
    "    813: 'White-Asian-Hawaiian/Pacific Islander',\n",
    "    814: 'White-Black-American Indian-Asian',\n",
    "    815: 'American Indian-Hawaiian/Pacific Islander',\n",
    "    816: 'White-Black--Hawaiian/Pacific Islander',\n",
    "    817: 'White-American Indian-Hawaiian/Pacific Islander',\n",
    "    818: 'Black-American Indian-Asian',\n",
    "    819: 'White-American Indian-Asian-Hawaiian/Pacific Islander',\n",
    "    820: 'Two or three races, unspecified',\n",
    "    830: 'Four or five races, unspecified',\n",
    "    999: 'Blank'},\n",
    "    'MARST': {1: 'Married, spouse present',\n",
    "    2: 'Married, spouse absent',\n",
    "    3: 'Separated',\n",
    "    4: 'Divorced',\n",
    "    5: 'Widowed',\n",
    "    6: 'Never married/single',\n",
    "    7: 'Widowed or Divorced',\n",
    "    9: 'NIU'},\n",
    "    'CITIZEN': {1: 'Born in U.S',\n",
    "    2: 'Born in U.S. outlying',\n",
    "    3: 'Born abroad of American parents',\n",
    "    4: 'Naturalized citizen',\n",
    "    5: 'Not a citizen',\n",
    "    9: 'NIU'},\n",
    "    'WORKLY': {0: 'NIU',\n",
    "    1: 'No',\n",
    "    2: 'Yes'},\n",
    "    'CLASSWKR': {0: 'NIU',\n",
    "    10: 'Self-employed',\n",
    "    13: 'Self-employed, not incorporated',\n",
    "    14: 'Self-employed, incorporated',\n",
    "    20: 'Works for wages or salary',\n",
    "    21: 'Wage/salary, private',\n",
    "    22: 'Private, for profit',\n",
    "    23: 'Private, nonprofit',\n",
    "    24: 'Wage/salary, government',\n",
    "    25: 'Federal government employee',\n",
    "    26: 'Armed forces',\n",
    "    27: 'State government employee',\n",
    "    28: 'Local government employee',\n",
    "    29: 'Unpaid family worker',\n",
    "    99: 'Missing/Unknown'},\n",
    "    'EDUC': {0: 'NIU or no schooling',\n",
    "    1: 'NIU or blank',\n",
    "    2: 'None or preschool',\n",
    "    10: 'Grades 1, 2, 3, or 4',\n",
    "    11: 'Grade 1',\n",
    "    12: 'Grade 2',\n",
    "    13: 'Grade 3',\n",
    "    14: 'Grade 4',\n",
    "    20: 'Grades 5 or 6',\n",
    "    21: 'Grade 5',\n",
    "    22: 'Grade 6',\n",
    "    30: 'Grades 7 or 8',\n",
    "    31: 'Grade 7',\n",
    "    32: 'Grade 8',\n",
    "    40: 'Grade 9',\n",
    "    50: 'Grade 10',\n",
    "    60: 'Grade 11',\n",
    "    70: 'Grade 12',\n",
    "    71: '12th grade, no diploma',\n",
    "    72: '12th grade, diploma unclear',\n",
    "    73: 'High school diploma or equivalent',\n",
    "    80: '1 year of college',\n",
    "    81: 'Some college but no degree',\n",
    "    90: '2 years of college',\n",
    "    91: \"Associate's degree, occupational/vocational program\",\n",
    "    92: \"Associate's degree, academic program\",\n",
    "    100: '3 years of college',\n",
    "    110: '4 years of college',\n",
    "    111: \"Bachelor's degree\",\n",
    "    120: '5+ years of college',\n",
    "    121: '5 years of college',\n",
    "    122: '6+ years of college',\n",
    "    123: \"Master's degree\",\n",
    "    124: 'Professional school degree',\n",
    "    125: 'Doctorate degree',\n",
    "    999: 'Missing/Unknown'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8eef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RELATE', 'AGE', 'SEX', 'RACE', 'MARST', 'CITIZEN', 'CLASSWKR', 'EDUC', 'WORKLY', 'INCTOT']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./2011_2019_D.csv\")\n",
    "col_names = list(df.columns)\n",
    "print(col_names)\n",
    "\n",
    "rel = list(code_dict['RELATE'].values())\n",
    "age = [i for i in range(0, 80)] + [80, 85] # https://cps.ipums.org/cps-action/variables/AGE#codes_section\n",
    "sex = list(code_dict['SEX'].values())\n",
    "rac = list(code_dict['RACE'].values())\n",
    "mar = list(code_dict['MARST'].values())\n",
    "cit = list(code_dict['CITIZEN'].values())\n",
    "wor = list(code_dict['WORKLY'].values())\n",
    "cla = list(code_dict['CLASSWKR'].values())\n",
    "edu = list(code_dict['EDUC'].values())\n",
    "inc = [0, 500000] # https://cps.ipums.org/cps-action/variables/INCTOT#codes_section\n",
    "\n",
    "df_D_s = pd.read_csv(\"./2011_2019_D_s.csv\")\n",
    "df_D_s['AGE'] = df_D_s['AGE'].astype(int)\n",
    "df_D_s['INCTOT'] = df_D_s['INCTOT'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d5667",
   "metadata": {},
   "source": [
    "---\n",
    "# Variables $\\epsilon, \\tau, \\beta$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa0db1",
   "metadata": {},
   "source": [
    "# Detect FP/FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "901f52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FP_FN(re, q_D, q_D_s, tau):\n",
    "    if (re == 0 and (q_D_s - tau < q_D and q_D < q_D_s + tau)):\n",
    "        return 'FN'\n",
    "    if (re == 1 and (q_D <= q_D_s - tau or q_D >= q_D_s + tau)):\n",
    "        return 'FP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b382d1",
   "metadata": {},
   "source": [
    "# $LM_{sum}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e5dddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lmsum(q, A_i, dom_A_i, df, df_D_s, tau, eps, f_handle):\n",
    "    re = -1\n",
    "    \n",
    "    q_D = get_sum(df, q, A_i)\n",
    "    q_D_s = get_sum(df_D_s, q, A_i)\n",
    "    l = q_D_s - tau\n",
    "    r = q_D_s + tau\n",
    "    \n",
    "    f_handle.write(\"(I = (%s, %s), Truth = %s, eps = %s) Algo returns:\\n\" \n",
    "          %(l, r, \"Distance bound satisfied\" if (l < q_D and q_D < r) else \"Distance bound unmet\", eps))\n",
    "    # ----------------------------------------------------------------------------------------------------------------\n",
    "    GS_Q = max(dom_A_i) - min(dom_A_i)\n",
    "    nu_q = np.random.laplace(scale = GS_Q/eps)\n",
    "    f_handle.write(\"\\tDP estimate = %s + %s = %s\\n\" %(q_D, nu_q, q_D + nu_q))\n",
    "    \n",
    "    if -1*tau < q_D + nu_q - q_D_s and q_D + nu_q - q_D_s < tau:\n",
    "        f_handle.write(\"Distance bound satisfied\\n\")\n",
    "        re = 1\n",
    "    else:\n",
    "        f_handle.write(\"Distance bound unmet\\n\")\n",
    "        re = 0\n",
    "    return re, q_D, q_D_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb150e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_lmsum(q, A_i, dom_A_i, df, df_D_s, tau, eps, f_handle):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    for i in range(100):\n",
    "        re, q_D, q_D_s = lmsum(q, A_i, dom_A_i, df, df_D_s, tau, eps, f_handle)\n",
    "        tmp = FP_FN(re, q_D, q_D_s, tau)\n",
    "        if tmp == 'FN':\n",
    "            FN += 1\n",
    "        if tmp == 'FP':\n",
    "            FP += 1\n",
    "    err = (FN + FP)/100\n",
    "    f_handle.write(\"\\n\")\n",
    "    \n",
    "    print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242ea3e",
   "metadata": {},
   "source": [
    "# $R2T_{sum}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2135a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2tsum(q, A_i, dom_A_i, df, df_D_s, tau, eps, beta, f_handle):\n",
    "    re = -1\n",
    "    \n",
    "    q_D = get_sum(df, q, A_i)\n",
    "    q_D_s = get_sum(df_D_s, q, A_i)\n",
    "    l = q_D_s - tau\n",
    "    r = q_D_s + tau\n",
    "    \n",
    "    f_handle.write(\"(I = (%s, %s), Truth = %s, eps = %s) Algo returns:\\n\" \n",
    "          %(l, r, \"Distance bound satisfied\" if (l < q_D and q_D < r) else \"Distance bound unmet\", eps))\n",
    "    # ----------------------------------------------------------------------------------------------------------------\n",
    "    GS_Q = max(dom_A_i) - min(dom_A_i)\n",
    "    log_GS_Q = math.ceil(math.log(GS_Q, 2))\n",
    "    \n",
    "    Q = []\n",
    "    trunc_thres = []\n",
    "    for i in range(1, log_GS_Q + 1):\n",
    "        new_conjunct = copy.deepcopy(q)\n",
    "        if A_i in new_conjunct:\n",
    "            new_conjunct[A_i].append(['<=', 2**i])\n",
    "        else:\n",
    "            new_conjunct[A_i] = [['<=', 2**i]]\n",
    "#         print(\"(R2T) %s\" %(new_conjunct))\n",
    "        \n",
    "        Q.append(new_conjunct)\n",
    "        trunc_thres.append(2**i)\n",
    "    if log_GS_Q == 0:                                # Binary domain\n",
    "        new_conjunct = copy.deepcopy(q)\n",
    "        if A_i in new_conjunct:\n",
    "            new_conjunct[A_i].append(['<=', 2])\n",
    "        else:\n",
    "            new_conjunct[A_i] = [['<=', 2]]\n",
    "#         print(\"(R2T) %s\" %(new_conjunct))\n",
    "        \n",
    "        Q.append(new_conjunct)\n",
    "        trunc_thres = [2]\n",
    "    f_handle.write(\"Truncation thresholds: %s\\n\" %(trunc_thres))\n",
    "    \n",
    "    max_across_Q = 0\n",
    "    for i in range(len(Q)):\n",
    "        q_i = get_sum(df, Q[i], A_i)\n",
    "        GS_q_i = trunc_thres[i]                      # tau^j\n",
    "        f_handle.write(\"\\tIter# %s: q(D) = %s with truncation threshold of %s\\n\" %(i, q_i, GS_q_i))\n",
    "        \n",
    "        nu_q_i = np.random.laplace(scale = log_GS_Q * GS_q_i / eps)\n",
    "        penalty = (log_GS_Q * math.log(log_GS_Q/beta) * GS_q_i) / eps\n",
    "        noisy_q_i = q_i + nu_q_i - penalty\n",
    "        f_handle.write(\"\\t\\t(eqn 7, noisy estimate) %.3f\\n\" %(noisy_q_i))\n",
    "        \n",
    "        if noisy_q_i > max_across_Q:\n",
    "            max_across_Q = noisy_q_i\n",
    "    \n",
    "    f_handle.write(\"(noisy)%.3f - %.3f = %.3f\\n\" %(max_across_Q, q_D_s, max_across_Q - q_D_s))\n",
    "    if -1*tau < max_across_Q - q_D_s and max_across_Q - q_D_s < tau:\n",
    "        f_handle.write(\"Distance bound satisfied\\n\")\n",
    "        re = 1\n",
    "    else:\n",
    "        f_handle.write(\"Distance bound unmet\\n\")\n",
    "        re = 0\n",
    "    return re, q_D, q_D_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e1d7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_r2tsum(q, A_i, dom_A_i, df, df_D_s, tau, eps, beta, f_handle):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    for i in range(100):\n",
    "        re, q_D, q_D_s = r2tsum(q, A_i, dom_A_i, df, df_D_s, tau, eps, beta, f_handle)\n",
    "        tmp = FP_FN(re, q_D, q_D_s, tau)\n",
    "        if tmp == 'FN':\n",
    "            FN += 1\n",
    "        if tmp == 'FP':\n",
    "            FP += 1\n",
    "    err = (FN + FP)/100\n",
    "    f_handle.write(\"\\n\")\n",
    "    \n",
    "    print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84275b97",
   "metadata": {},
   "source": [
    "# $SVT_{sum}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc47a8d",
   "metadata": {},
   "source": [
    "## - Find $t_j$ to stop at in $SVT_{sum}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed39cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def private_bound_DS(q, A_i, GS_Q, df, eps, theta, f_handle):\n",
    "    nu_q = np.random.laplace(scale = 1/(eps/3))\n",
    "    tilde_n = get_query_result(df, q) + nu_q\n",
    "    \n",
    "    rho = np.random.laplace(scale = 1/(eps/3))\n",
    "    \n",
    "    for i in range(1, math.ceil(math.log(GS_Q, 2)) + 1):\n",
    "        new_conjunct = copy.deepcopy(q)\n",
    "        if A_i in new_conjunct:\n",
    "            new_conjunct[A_i].append(['<=', 2**i])\n",
    "        else:\n",
    "            new_conjunct[A_i] = [['<=', 2**i]]\n",
    "#         print(\"(Private bound) %s\" %(new_conjunct))\n",
    "        \n",
    "        nu_q_c = np.random.laplace(scale = 1/(eps/3))\n",
    "        q_c = get_query_result(df, new_conjunct)\n",
    "        \n",
    "        if q_c + nu_q_c >= theta*tilde_n + rho:\n",
    "            return i\n",
    "    return math.ceil(math.log(GS_Q, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4e63396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nu_q_i: queries are monotonic - \"all queries whose answers are different change in the same direction\"\n",
    "def SVT_ith_q(eps_2, df, q_i, GS_q_i, T, rho, f_handle):\n",
    "    nu_q_i = np.random.laplace(scale = 1/eps_2)\n",
    "    noisy_q_i = q_i/GS_q_i + nu_q_i\n",
    "\n",
    "    T_i = T/GS_q_i\n",
    "    noisy_T_i = T_i + rho\n",
    "    \n",
    "    f_handle.write(\"\\t\\tCheck: %.3f (=%.3f + %.3f) >= %.3f (=%.3f + %.3f)?\\n\" %(noisy_q_i, q_i/GS_q_i, nu_q_i, \n",
    "                                                                                noisy_T_i, T_i, rho))\n",
    "    return noisy_q_i, noisy_T_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9e85a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svtsum(q, A_i, dom_A_i, df, df_D_s, tau, eps, f_handle):\n",
    "    re = -1\n",
    "    \n",
    "    q_D = get_sum(df, q, A_i)\n",
    "    q_D_s = get_sum(df_D_s, q, A_i)\n",
    "    l = q_D_s - tau\n",
    "    r = q_D_s + tau\n",
    "    \n",
    "    f_handle.write(\"(I = (%s, %s), Truth = %s, eps = %s) Algo returns:\\n\" \n",
    "          %(l, r, \"Distance bound satisfied\" if (l < q_D and q_D < r) else \"Distance bound unmet\", eps))\n",
    "    # ----------------------------------------------------------------------------------------------------------------\n",
    "    GS_Q = max(dom_A_i) - min(dom_A_i)\n",
    "    \n",
    "    Q = []\n",
    "    trunc_thres = []\n",
    "    for i in range(1, private_bound_DS(q, A_i, GS_Q, df, eps/3, 0.95, f_handle) + 1):\n",
    "        new_conjunct = copy.deepcopy(q)\n",
    "        if A_i in new_conjunct:\n",
    "            new_conjunct[A_i].append(['<=', 2**i])\n",
    "        else:\n",
    "            new_conjunct[A_i] = [['<=', 2**i]]\n",
    "#         print(\"(R2T) %s\" %(new_conjunct))\n",
    "        \n",
    "        Q.append(new_conjunct)\n",
    "        trunc_thres.append(2**i)\n",
    "    if math.ceil(math.log(GS_Q, 2)) == 0:            # Binary domain\n",
    "        new_conjunct = copy.deepcopy(q)\n",
    "        if A_i in new_conjunct:\n",
    "            new_conjunct[A_i].append(['<=', 2])\n",
    "        else:\n",
    "            new_conjunct[A_i] = [['<=', 2]]\n",
    "#         print(\"(R2T) %s\" %(new_conjunct))\n",
    "        \n",
    "        Q.append(new_conjunct)\n",
    "        trunc_thres = [2]\n",
    "    f_handle.write(\"Truncation thresholds: %s\\n\" %(trunc_thres))\n",
    "    \n",
    "    eps_1 = eps_2 = eps/3\n",
    "    rho = np.random.laplace(scale = 1/eps_1)\n",
    "        \n",
    "    f_handle.write(\"Check if any sum >= r:\\n\")\n",
    "    for i in range(len(Q)):\n",
    "        q_i = get_sum(df, Q[i], A_i)\n",
    "        GS_q_i = trunc_thres[i]\n",
    "        f_handle.write(\"\\tIter# %s: q(D) = %s with truncation threshold of %s\\n\" %(i, q_i, GS_q_i))\n",
    "        \n",
    "        noisy_q_i, noisy_T_i = SVT_ith_q(eps_2, df, q_i, GS_q_i, r, rho, f_handle)\n",
    "        if noisy_q_i >= noisy_T_i:\n",
    "            f_handle.write(\"Distance bound unmet\\n\")\n",
    "            re = 0\n",
    "            return re, q_D, q_D_s\n",
    "    \n",
    "    f_handle.write(\"Check if any sum >= l+1:\\n\")\n",
    "    for i in range(len(Q)):\n",
    "        q_i = get_sum(df, Q[i], A_i)\n",
    "        GS_q_i = trunc_thres[i]\n",
    "        f_handle.write(\"\\tIter# %s: q(D) = %s with truncation threshold of %s\\n\" %(i, q_i, GS_q_i))\n",
    "        \n",
    "        noisy_q_i, noisy_T_i = SVT_ith_q(eps_2, df, q_i, GS_q_i, l+1, rho, f_handle)\n",
    "        if noisy_q_i >= noisy_T_i:\n",
    "            f_handle.write(\"Distance bound satisfied\\n\")\n",
    "            re = 1\n",
    "            return re, q_D, q_D_s\n",
    "    \n",
    "    f_handle.write(\"Distance bound unmet\\n\")\n",
    "    re = 0\n",
    "    return re, q_D, q_D_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "465953d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_svtsum(q, A_i, dom_A_i, df, df_D_s, tau, eps, f_handle):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    for i in range(100):\n",
    "        re, q_D, q_D_s = svtsum(q, A_i, dom_A_i, df, df_D_s, tau, eps, f_handle)\n",
    "        tmp = FP_FN(re, q_D, q_D_s, tau)\n",
    "        if tmp == 'FN':\n",
    "            FN += 1\n",
    "        if tmp == 'FP':\n",
    "            FP += 1\n",
    "    err = (FN + FP)/100\n",
    "    f_handle.write(\"\\n\")\n",
    "    \n",
    "    print(\"---- %s seconds ----\" % (time.time() - start_time))\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e0b630",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 9 queries (3 small, 3 medium, 3 large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6e8b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = {'SEX': [['==', 'Female']], 'RACE': [['==', 'White-Black']], 'WORKLY': [['==', 'No']]}\n",
    "q2 = {'RACE': [['==', 'Asian only']], 'MARST': [['==', \"Separated\"]], 'CITIZEN': [['==', 'Born in U.S']]} \n",
    "q3 = {'SEX': [['==', 'Male']], 'EDUC': [['==', \"Professional school degree\"]], 'MARST': [['==', 'Married, spouse absent']]} \n",
    "\n",
    "q6 = {'SEX': [['==', 'Male']], 'RACE': [['==', 'Asian only']], 'WORKLY': [['==', 'No']]}    \n",
    "q5 = {'SEX': [['==', 'Female']], 'EDUC': [['==', \"Master's degree\"]], 'MARST': [['==', 'Widowed']]} \n",
    "q4 = {'RACE': [['==', 'White']], 'MARST': [['==', \"Divorced\"]], 'CITIZEN': [['==', 'Not a citizen']]} \n",
    "\n",
    "q7 = {'SEX': [['==', 'Male']], 'RACE': [['==', 'Black']], 'WORKLY': [['==', 'No']]}\n",
    "q8 = {'SEX': [['==', 'Female']], 'EDUC': [['==', \"High school diploma or equivalent\"]], 'MARST': [['==', 'Never married/single']]}\n",
    "q9 = {'RACE': [['==', 'White']], 'MARST': [['==', \"Married, spouse present\"]], 'CITIZEN': [['==', 'Born in U.S']]}\n",
    "\n",
    "queries = [q1, q2, q3, q4, q5, q6, q7, q8, q9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97f564f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_(q):\n",
    "    print('DS_qd = %s, q(D) = %s, q(D_s) = %s'%(helper_apply_pred(df, q)['INCTOT'].max(), \n",
    "                                                get_sum(df, q,'INCTOT'), \n",
    "                                                get_sum(df_D_s, q,'INCTOT')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "788eac9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1:\n",
      "DS_qd = 127764, q(D) = 6915340, q(D_s) = 6942866\n",
      "q2:\n",
      "DS_qd = 359892, q(D) = 7653748, q(D_s) = 7818555\n",
      "q3:\n",
      "DS_qd = 439420, q(D) = 9891949, q(D_s) = 10129562\n",
      "q4:\n",
      "DS_qd = 500000, q(D) = 123543040, q(D_s) = 128497757\n",
      "q5:\n",
      "DS_qd = 384842, q(D) = 138131505, q(D_s) = 139557517\n",
      "q6:\n",
      "DS_qd = 278011, q(D) = 143179279, q(D_s) = 149069654\n",
      "q7:\n",
      "DS_qd = 276799, q(D) = 327036909, q(D_s) = 336130017\n",
      "q8:\n",
      "DS_qd = 403353, q(D) = 685635093, q(D_s) = 690711885\n",
      "q9:\n",
      "DS_qd = 500000, q(D) = 23542765109, q(D_s) = 23434676868\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "for i in queries:\n",
    "    print('q'+ str(num) + \":\")\n",
    "    print_(i)\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5807afb1",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bccba490",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_frac = [0.002, 0.008, 0.032, 0.128, 0.512]   \n",
    "default_eps = 0.25\n",
    "\n",
    "eps = [0.0625, 0.125, 0.25, 0.5, 1]   \n",
    "default_tau = 0.032\n",
    "\n",
    "delta = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34f8ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_LM_vary_tau = [[], [], [], [], [], [], [], [], []]\n",
    "lst_LM_vary_eps = [[], [], [], [], [], [], [], [], []]\n",
    "\n",
    "lst_R2T_vary_tau = [[], [], [], [], [], [], [], [], []]\n",
    "lst_R2T_vary_eps = [[], [], [], [], [], [], [], [], []]\n",
    "\n",
    "lst_SVT_vary_tau = [[], [], [], [], [], [], [], [], []]\n",
    "lst_SVT_vary_eps = [[], [], [], [], [], [], [], [], []]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c6688",
   "metadata": {},
   "source": [
    "# SVT---vary tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e5cbd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 1009.0693328380585 seconds ----\n",
      "---- 918.858788728714 seconds ----\n",
      "---- 866.0344231128693 seconds ----\n",
      "---- 860.2647318840027 seconds ----\n",
      "---- 878.1858758926392 seconds ----\n",
      "\n",
      "---- 331.79641604423523 seconds ----\n",
      "---- 328.04704904556274 seconds ----\n",
      "---- 355.99049377441406 seconds ----\n",
      "---- 345.1483190059662 seconds ----\n",
      "---- 383.94701623916626 seconds ----\n",
      "\n",
      "---- 563.1433279514313 seconds ----\n",
      "---- 603.8743057250977 seconds ----\n",
      "---- 549.4840550422668 seconds ----\n",
      "---- 636.3955688476562 seconds ----\n",
      "---- 583.470342874527 seconds ----\n",
      "\n",
      "---- 1161.9958453178406 seconds ----\n",
      "---- 1166.5971539020538 seconds ----\n",
      "---- 1162.6101169586182 seconds ----\n",
      "---- 1157.6727690696716 seconds ----\n",
      "---- 1130.871166229248 seconds ----\n",
      "\n",
      "---- 946.936793088913 seconds ----\n",
      "---- 933.7476987838745 seconds ----\n",
      "---- 954.7622430324554 seconds ----\n",
      "---- 920.8158740997314 seconds ----\n",
      "---- 898.3519458770752 seconds ----\n",
      "\n",
      "---- 788.9373109340668 seconds ----\n",
      "---- 791.3045318126678 seconds ----\n",
      "---- 788.5504529476166 seconds ----\n",
      "---- 784.837691783905 seconds ----\n",
      "---- 781.3954582214355 seconds ----\n",
      "\n",
      "---- 827.3244287967682 seconds ----\n",
      "---- 835.3078470230103 seconds ----\n",
      "---- 833.4984059333801 seconds ----\n",
      "---- 834.2695248126984 seconds ----\n",
      "---- 818.2794060707092 seconds ----\n",
      "\n",
      "---- 951.5862772464752 seconds ----\n",
      "---- 951.8472776412964 seconds ----\n",
      "---- 950.7658281326294 seconds ----\n",
      "---- 949.6468091011047 seconds ----\n",
      "---- 933.6602430343628 seconds ----\n",
      "\n",
      "---- 1778.3328161239624 seconds ----\n",
      "---- 1776.0619909763336 seconds ----\n",
      "---- 1775.607122182846 seconds ----\n",
      "---- 1775.3485760688782 seconds ----\n",
      "---- 1732.142659664154 seconds ----\n",
      "\n",
      "[[0.05, 0.91, 0.9, 0.88, 0.2], [0.06, 0.09, 0.86, 0.89, 0.55], [0.08, 0.08, 0.92, 0.86, 0.8], [0.02, 0.0, 0.02, 0.85, 0.0], [0.07, 0.06, 0.86, 0.48, 0.0], [0.0, 0.0, 0.0, 0.98, 0.0], [0.0, 0.0, 1.0, 1.0, 0.0], [0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "f_handle = open('sum_SVT_vary_tau.txt', 'w')\n",
    "num = 0\n",
    "for i in queries:\n",
    "    f_handle.write(\"%s\\n\" %(i))\n",
    "    q_D_s = get_sum(df_D_s, i, 'INCTOT')\n",
    "    lst_SVT_vary_tau[num].append(err_svtsum(i, 'INCTOT', inc, df, df_D_s, tau_frac[0]*q_D_s, default_eps, f_handle))\n",
    "    lst_SVT_vary_tau[num].append(err_svtsum(i, 'INCTOT', inc, df, df_D_s, tau_frac[1]*q_D_s, default_eps, f_handle))\n",
    "    lst_SVT_vary_tau[num].append(err_svtsum(i, 'INCTOT', inc, df, df_D_s, tau_frac[2]*q_D_s, default_eps, f_handle))\n",
    "    lst_SVT_vary_tau[num].append(err_svtsum(i, 'INCTOT', inc, df, df_D_s, tau_frac[3]*q_D_s, default_eps, f_handle))\n",
    "    lst_SVT_vary_tau[num].append(err_svtsum(i, 'INCTOT', inc, df, df_D_s, tau_frac[4]*q_D_s, default_eps, f_handle))\n",
    "    print()\n",
    "    num = num + 1\n",
    "f_handle.close()\n",
    "print(lst_SVT_vary_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49407c79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
